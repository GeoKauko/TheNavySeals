{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeoKauko/TheNavySeals/blob/main/1_Training_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvwz6WwMQT73"
      },
      "source": [
        "#SealNN training notebook\n",
        "This notebook contains the image processing of MAXAR satellite images and the training of the deep learning.\n",
        "The input requires the satellite image as .tif and seal annotations as .shp. The output is a the SealNN model that will be used in detecting seals in the following post-processing notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6aaHDKWQx81"
      },
      "source": [
        "###Import libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGGDhrMXQ7uV"
      },
      "source": [
        "Install and import required packages and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oJNA5UFYrG53"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision segmentation-models-pytorch tifffile tabulate rasterio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dyKx_RuY9L7f"
      },
      "outputs": [],
      "source": [
        "## Import libraries for image processing\n",
        "import os\n",
        "from os import path\n",
        "import os.path\n",
        "from osgeo import gdal\n",
        "import rasterio\n",
        "from rasterio import windows\n",
        "from rasterio.windows import Window\n",
        "from rasterio.plot import reshape_as_image\n",
        "import rasterio.mask\n",
        "from rasterio.features import rasterize, geometry_mask\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import mapping, Point, box, Polygon\n",
        "from shapely.ops import cascaded_union\n",
        "import numpy as np\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "\n",
        "## Import libraries for training\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision.transforms import v2 as transforms\n",
        "import torchvision.transforms.functional as TF\n",
        "import segmentation_models_pytorch as smp\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile\n",
        "from PIL import Image\n",
        "import time\n",
        "from tabulate import tabulate\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kAyYEKRRFFg"
      },
      "source": [
        "Connect to Google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sfFiemxubfj",
        "outputId": "0ed32e62-573a-4b34-8784-ff73905eb478"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "## GOOGLE COLAB USERS ONLY\n",
        "## Mount Google Drive for data retrieval\n",
        "drive.mount('/content/drive')\n",
        "project_path = '/content/drive/My Drive/TheNavySeals/' # Change the file path to your own"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQyWXLnORMIu"
      },
      "source": [
        "Or connect to local drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-oRfHVnwMUEW"
      },
      "outputs": [],
      "source": [
        "# ## LOCAL USERS ONLY\n",
        "# ## Change the path to your project directory\n",
        "\n",
        "# os.chdir('D:\\E_2024_P6\\SEAL')\n",
        "\n",
        "# project_path = ''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfUci_LfbB7O"
      },
      "source": [
        "### Functions for image processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ccVmVzsg9VQ3"
      },
      "outputs": [],
      "source": [
        "## Reduce the radiometric resolution of a raster to 8 bits\n",
        "def reduce_radiometric_resolution(input_path, output_path, input_res=11):\n",
        "    \"\"\"\n",
        "    Reduce the radiometric resolution of the input raster and save the output raster.\n",
        "\n",
        "    Args:\n",
        "    - input_path (string): Path to the input raster.\n",
        "    - output_path (string): Path to the output raster.\n",
        "    - input_res (int): Radiometric resolution of the input raster in bits.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Ensure the output directory exists\n",
        "    output_dir = os.path.dirname(output_path)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    with rasterio.open(input_path) as src:\n",
        "        # Read the number of bands\n",
        "        num_bands = src.count\n",
        "\n",
        "        # Initialize an array to store the scaled bands\n",
        "        scaled_arrays = []\n",
        "\n",
        "        for band in range(1, num_bands + 1):\n",
        "            # Read the image band as a numpy array\n",
        "            image_array = src.read(band, masked=True)\n",
        "\n",
        "            # Rescale the pixel values to fit within 8-bit range (0-255)\n",
        "            scaled_array = (image_array / (2**input_res - 1) * 255).astype(np.uint8)\n",
        "\n",
        "            # Append the scaled array to the list\n",
        "            scaled_arrays.append(scaled_array)\n",
        "\n",
        "        # Stack the scaled arrays along the first axis to create a 3D array\n",
        "        scaled_arrays = np.stack(scaled_arrays, axis=0)\n",
        "\n",
        "        # Create a new raster profile with 8-bit pixel depth\n",
        "        profile = src.profile\n",
        "        profile.update(dtype=rasterio.uint8, count=num_bands)\n",
        "\n",
        "        # Write the scaled arrays to a new raster file\n",
        "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "            dst.write(scaled_arrays)\n",
        "\n",
        "\n",
        "\n",
        "def resize_rasters_in_folder(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Reduces the radiometric resolution of all rasters in a folder and saves the output rasters in the output_folder.\n",
        "\n",
        "    Args:\n",
        "    - input_folder (string): Path to the input folder.\n",
        "    - output_folder (string): Path to the output folder.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Iterate over each file in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        # Ensure we're only processing files (not subdirectories)\n",
        "        if os.path.isfile(input_path):\n",
        "            output_path = os.path.join(output_folder, filename)\n",
        "            reduce_radiometric_resolution(input_path, output_path)\n",
        "\n",
        "\n",
        "## Mask raster\n",
        "def create_polygon_from_pixels(row, col, transform):\n",
        "    \"\"\"\n",
        "    Creates a polygon from a center pixel (row, col) and its 24 surrounding pixels (5x5 block).\n",
        "\n",
        "    Args:\n",
        "    - row (int): The row index of the center pixel.\n",
        "    - col (int): The column index of the center pixel.\n",
        "    - transform (tuple): A tuple of 6 elements representing the affine transformation coefficients \n",
        "                         (a, b, c, d, e, f) which map pixel coordinates (x, y) to geographic coordinates (X, Y):\n",
        "                         X = a + b * x + c * y\n",
        "                         Y = d + e * x + f * y\n",
        "                         \n",
        "    Returns:\n",
        "    - Polygon: A polygon representing the 5x5 block of pixels centered around the given pixel.\n",
        "    \"\"\"\n",
        "    # Calculate the coordinates of the top-left corner of the top-left pixel\n",
        "    top_left_x = transform[0] + (col - 2) * transform[1] + (row - 2) * transform[2]\n",
        "    top_left_y = transform[3] + (col - 2) * transform[4] + (row - 2) * transform[5]\n",
        "\n",
        "    # Pixel dimensions\n",
        "    pixel_width = abs(transform[1])\n",
        "    pixel_height = abs(transform[5])\n",
        "\n",
        "    # Calculate the coordinates for the 5x5 block of pixels\n",
        "    polygon_coords = [\n",
        "        (top_left_x, top_left_y),\n",
        "        (top_left_x + 5 * pixel_width, top_left_y),\n",
        "        (top_left_x + 5 * pixel_width, top_left_y - 5 * pixel_height),\n",
        "        (top_left_x, top_left_y - 5 * pixel_height),\n",
        "        (top_left_x, top_left_y)\n",
        "    ]\n",
        "\n",
        "    return Polygon(polygon_coords)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def raster_points_to_polygons(raster_path, shapefile_path):\n",
        "    \"\"\"\n",
        "    Converts point geometries in a shapefile to polygons representing a 5x5 block of pixels \n",
        "    in the raster centered around the point.\n",
        "\n",
        "    Args:\n",
        "    - raster_path (string): Path to the input raster file.\n",
        "    - shapefile_path (string): Path to the input shapefile containing point geometries.\n",
        "    \n",
        "    Returns:\n",
        "    - GeoDataFrame: A GeoDataFrame containing polygons representing the 5x5 blocks of pixels \n",
        "      centered around the points in the input shapefile.\n",
        "    \"\"\"\n",
        "    # Read raster data\n",
        "    raster_dataset = gdal.Open(raster_path)\n",
        "    raster_geotransform = raster_dataset.GetGeoTransform()\n",
        "\n",
        "    # Read shapefile\n",
        "    shapefile_gdf = gpd.read_file(shapefile_path)\n",
        "    shape_crs = shapefile_gdf.crs\n",
        "\n",
        "    polygons = []\n",
        "    for point in shapefile_gdf.geometry:\n",
        "        # Convert point coordinates to raster coordinates\n",
        "        x, y = point.x, point.y\n",
        "        col = int((x - raster_geotransform[0]) / raster_geotransform[1])\n",
        "        row = int((y - raster_geotransform[3]) / raster_geotransform[5])\n",
        "\n",
        "        # Create polygon around the pixel and its 24 surrounding pixels\n",
        "        polygon = create_polygon_from_pixels(row, col, raster_geotransform)\n",
        "        polygons.append(polygon)\n",
        "\n",
        "    result_gdf = gpd.GeoDataFrame(geometry=polygons, crs=shape_crs)\n",
        "\n",
        "    return result_gdf\n",
        "\n",
        "def mask_raster_with_polygon(input_raster_path, polygons, output_raster_path, value=1):\n",
        "    \"\"\"\n",
        "    Creates a copy of a raster, set all its values to 0, overlay it with a polygon shapefile,\n",
        "    and set all pixels underneath polygons to a specified value.\n",
        "\n",
        "    Args:\n",
        "    - input_raster_path (str): Path to the input raster.\n",
        "    - polygons (gdf): GeoDataFrame with the polygons of the mask.\n",
        "    - output_raster_path (str): Path to save the masked raster.\n",
        "    - value (int, optional): Value to set for pixels underneath polygons. Defaults to 1.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Open the input raster for reading\n",
        "    with rasterio.open(input_raster_path) as src:\n",
        "        # Read raster data\n",
        "        raster_data = src.read(1)\n",
        "        # Get metadata\n",
        "        meta = src.meta\n",
        "\n",
        "    # Set all values to 0\n",
        "    raster_data.fill(0)\n",
        "\n",
        "    # Create mask from polygons\n",
        "    mask = geometry_mask(polygons.geometry, out_shape=raster_data.shape, transform=src.transform, invert=True)\n",
        "\n",
        "    # Set pixels underneath polygons to the specified value\n",
        "    raster_data[mask] = value\n",
        "\n",
        "    # Save the masked raster\n",
        "    with rasterio.open(output_raster_path, 'w', **meta) as dst:\n",
        "        dst.write(raster_data, 1)\n",
        "\n",
        "\n",
        "\n",
        "## Tile raster and mask to 224x224 px\n",
        "def split_and_save_raster(input_raster_path, part_width, part_height, output_folder):\n",
        "    \"\"\"\n",
        "    Splits a raster into multiple tiles of length part_width and height part_height, and save them in output_folder.\n",
        "\n",
        "    Args:\n",
        "    - input_raster_path: path to the input raster.\n",
        "    - part_width (int): Width of each tile.\n",
        "    - part_height (int): Height of each tile.\n",
        "    - output_folder (str): Directory to save the rasters.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # Open the raster\n",
        "    dataset = gdal.Open(input_raster_path)\n",
        "\n",
        "    # Get raster dimensions\n",
        "    width = dataset.RasterXSize\n",
        "    height = dataset.RasterYSize\n",
        "\n",
        "    # Calculate the number of parts\n",
        "    num_parts_x = width // part_width\n",
        "    num_parts_y = height // part_height\n",
        "\n",
        "    # Get the number of bands\n",
        "    bands = dataset.RasterCount\n",
        "\n",
        "    # Split the raster and save\n",
        "    for i in range(num_parts_x):\n",
        "        for j in range(num_parts_y):\n",
        "            x_offset = i * part_width\n",
        "            y_offset = j * part_height\n",
        "\n",
        "            # Read the split region\n",
        "            part = dataset.ReadAsArray(x_offset, y_offset, part_width, part_height)\n",
        "\n",
        "            # Expand dimensions if there's only one band\n",
        "            if bands == 1:\n",
        "               part = np.expand_dims(part, axis=0)\n",
        "\n",
        "            # Create a new GDAL dataset to save the split part\n",
        "            driver = gdal.GetDriverByName('GTiff')\n",
        "            output_path = os.path.join(output_folder, f'part_{i}_{j}.tif')\n",
        "            out_dataset = driver.Create(output_path, part_width, part_height, bands, gdal.GDT_UInt16)\n",
        "\n",
        "            # Write data to the new dataset\n",
        "            for band in range(bands):\n",
        "                out_band = out_dataset.GetRasterBand(band + 1)\n",
        "                out_band.WriteArray(part[band])\n",
        "\n",
        "            # Set georeference and projection\n",
        "            geo_transform = list(dataset.GetGeoTransform())\n",
        "            geo_transform[0] += x_offset * geo_transform[1]\n",
        "            geo_transform[3] += y_offset * geo_transform[5]\n",
        "            out_dataset.SetGeoTransform(tuple(geo_transform))\n",
        "            out_dataset.SetProjection(dataset.GetProjection())\n",
        "\n",
        "            # Save and close\n",
        "            out_dataset.FlushCache()\n",
        "            del out_dataset\n",
        "\n",
        "    # Close the original dataset\n",
        "    del dataset\n",
        "\n",
        "\n",
        "\n",
        "## Remove images and masks with no data values\n",
        "def contains_zero(input_raster_path):\n",
        "    \"\"\"\n",
        "    Checks if a single band raster has a zero value pixel.\n",
        "\n",
        "    Args:\n",
        "    - input_raster_path (str): Path to the input raster.\n",
        "\n",
        "    Returns:\n",
        "    - bool: True if the raster contains at least one zero value pixel, False otherwise.\n",
        "    \"\"\"\n",
        "    with rasterio.open(input_raster_path) as src:\n",
        "        # Read the image as a numpy array\n",
        "        raster_array = src.read(1)\n",
        "        # Check if the array contains any zero values\n",
        "        return (raster_array == 0).any()\n",
        "\n",
        "def remove_images_with_zero_panchromatic(directory, panchromatic_directory, mask_directory):\n",
        "    \"\"\"\n",
        "    Removes all images from a directory that contain a zero value pixel in their corresponding panchromatic image.\n",
        "    Also removes images with the same name from the mask directory.\n",
        "\n",
        "    Args:\n",
        "    - directory (str): Path to the directory containing the images to validate (pansharpened).\n",
        "    - panchromatic_directory (str): Path to the directory containing the panchromatic images with the same name.\n",
        "    - mask_directory (str): Path to the directory containing the mask images with the same name.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('.tif', '.tiff')):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            panchromatic_path = os.path.join(panchromatic_directory, filename)\n",
        "            if contains_zero(panchromatic_path):\n",
        "                os.remove(file_path)\n",
        "                print(f\"Removed image: {file_path}\")\n",
        "\n",
        "                # Remove the mask image with the same name\n",
        "                mask_path = os.path.join(mask_directory, filename)\n",
        "                if os.path.exists(mask_path):\n",
        "                    os.remove(mask_path)\n",
        "                    print(f\"Removed mask: {mask_path}\")\n",
        "\n",
        "\n",
        "                # Remove the pansharpened image with the same name\n",
        "                panchromatic_path = os.path.join(panchromatic_directory, filename)\n",
        "                if os.path.exists(panchromatic_path):\n",
        "                    os.remove(panchromatic_path)\n",
        "                    print(f\"Removed mask: {panchromatic_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Remove images and masks with no data values\n",
        "def contains_zero(input_raster_path):\n",
        "    \"\"\"\n",
        "    Checks if a single band raster has a zero value pixel.\n",
        "\n",
        "    Args:\n",
        "    - input_raster_path (str): Path to the input raster.\n",
        "\n",
        "    Returns:\n",
        "    - bool: True if the raster contains at least one zero value pixel, False otherwise.\n",
        "    \"\"\"\n",
        "    with rasterio.open(input_raster_path) as src:\n",
        "        # Read the image as a numpy array\n",
        "        raster_array = src.read(1)\n",
        "        # Check if the array contains any zero values\n",
        "        return (raster_array == 0).any()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Potentially this one can be used for multiple bands, but I have yet to test it\n",
        "def contains_zero_multiband(image_path):\n",
        "    \"\"\"\n",
        "    Check if an image has a zero value pixel in any of its bands.\n",
        "    \"\"\"\n",
        "    with rasterio.open(image_path) as src:\n",
        "        # Iterate through each band\n",
        "        for band in range(1, src.count + 1):\n",
        "            # Read the current band as a numpy array\n",
        "            image_array = src.read(band)\n",
        "            # Check if the array contains any zero values\n",
        "            if (image_array == 0).any():\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def remove_mulraster_with_zero_values(directory):\n",
        "    \"\"\"\n",
        "    Removes all rasters from a directory that contain a zero value pixel.\n",
        "\n",
        "    Args:\n",
        "    - directory (str): Path to the directory containing the images to validate.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('.tif', '.tiff')):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            if contains_zero_multiband(file_path):\n",
        "                os.remove(file_path)\n",
        "                #print(f\"Removed raster: {file_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def remove_zero_raster_mask(directory, mask_directory):\n",
        "    \"\"\"\n",
        "    Removes all rasters from a directory that contain a zero value pixel.\n",
        "    Also removes rasters with the same name from the mask directory.\n",
        "\n",
        "    Args:\n",
        "    - directory (str): Path to the directory containing the rasters to validate.\n",
        "    - mask_directory (str): Name of the folder containing the mask rasters with the same name.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('.tif', '.tiff')):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            if contains_zero(file_path):\n",
        "                os.remove(file_path)\n",
        "                # print(f\"Removed image: {file_path}\")\n",
        "\n",
        "                # Remove the image with the same name from the similar folder\n",
        "                mask_path = os.path.join(mask_directory, filename)\n",
        "                if os.path.exists(mask_path):\n",
        "                    os.remove(mask_path)\n",
        "                    # print(f\"Removed similar image: {mask_path}\")\n",
        "\n",
        "\n",
        "\n",
        "## Clip the raster masks to remove pixels above a certain threshold to more accurately represent the seal shape (Pan only)\n",
        "def update_masks(panchromatic_parts_path, mask_parts_path, threshold_value):\n",
        "    \"\"\"\n",
        "    Updates mask images based on corresponding panchromatic images. Specifically, for each mask,\n",
        "    all pixels with a value of 1 that correspond to pixels in the panchromatic image with a value above the\n",
        "    specified threshold are set to 0 in the new mask.\n",
        "\n",
        "    Args:\n",
        "    - panchromatic_parts_path (str): The directory path containing the panchromatic images.\n",
        "    - mask_parts_path (str): The directory path containing the mask images.\n",
        "    - threshold_value (int): The threshold value for the panchromatic image pixels. Pixels in the mask with a value of 1 and corresponding panchromatic image pixels above this threshold will be set to 0 in the new mask.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # List all mask files in the specified directory\n",
        "    mask_files = [f for f in os.listdir(mask_parts_path) if f.endswith('.tif')]\n",
        "\n",
        "    for mask_file in mask_files:\n",
        "        # Construct the full file paths for the mask and corresponding panchromatic image\n",
        "        mask_path = os.path.join(mask_parts_path, mask_file)\n",
        "        image_path = os.path.join(panchromatic_parts_path, mask_file)\n",
        "\n",
        "        # Read the panchromatic image\n",
        "        with rasterio.open(image_path) as img:\n",
        "            image_data = img.read(1)\n",
        "\n",
        "        # Read the mask image\n",
        "        with rasterio.open(mask_path) as mask:\n",
        "            mask_data = mask.read(1)\n",
        "            mask_meta = mask.meta\n",
        "\n",
        "        # Update the mask data based on the condition\n",
        "        new_mask_data = np.where((mask_data == 1) & (image_data > threshold_value), 0, mask_data)\n",
        "\n",
        "        # Save the new mask data overwriting the old mask\n",
        "        with rasterio.open(mask_path, 'w', **mask_meta) as mask:\n",
        "            mask.write(new_mask_data, 1)\n",
        "\n",
        "\n",
        "\n",
        "# def obtain_statistic(image_path, shapefile_path):\n",
        "#     '''\n",
        "#     Count the points that are within the bounds of an image and calculate the average pixel value.\n",
        "#     Args:\n",
        "#     - image_path (str): Path to the input raster.\n",
        "#     - shapefile_path (str): Path to the shapefile containing points.\n",
        "#     Returns:\n",
        "#     - num_points (int): Number of points within the image bounds.\n",
        "#     - avg_pixel_value (float): Average pixel value of the image.\n",
        "#     '''\n",
        "#     with rasterio.open(image_path) as src:\n",
        "#         image_bounds = src.bounds\n",
        "#         image_box = box(image_bounds.left, image_bounds.bottom, image_bounds.right, image_bounds.top)\n",
        "#         # Read the CRS from the image\n",
        "#         image_crs = src.crs\n",
        "#         # Calculate the average pixel value\n",
        "#         image_data = src.read(1)  # Read the first band\n",
        "#         avg_pixel_value = np.mean(image_data)\n",
        "#     shapefile = gpd.read_file(shapefile_path)\n",
        "\n",
        "#     shapefile['within_image'] = shapefile.apply(lambda row: image_box.contains(Point(row.geometry.x, row.geometry.y)), axis=1)\n",
        "#     points_within_image = shapefile[shapefile['within_image']]\n",
        "\n",
        "#     return len(points_within_image), avg_pixel_value\n",
        "\n",
        "# def obtain_statistics(image_dir, shapefile_path, csv_path):\n",
        "#     # List to store results\n",
        "#     results = []\n",
        "\n",
        "#     # Iterate through all images in the directory\n",
        "#     for image_name in os.listdir(image_dir):\n",
        "#         if image_name.endswith('.tif'):\n",
        "#             image_path = os.path.join(image_dir, image_name)\n",
        "#             num_points, avg_pixel_value = obtain_statistic(image_path, shapefile_path)\n",
        "#             results.append({'image_name': image_name, 'num_points': num_points, 'avg_pixel_value': avg_pixel_value})\n",
        "#             print(f'appended image {image_name}')\n",
        "#     # Convert results to DataFrame and save as CSV\n",
        "#     results_df = pd.DataFrame(results)\n",
        "#     results_df.to_csv(csv_path, index=False)\n",
        "\n",
        "#     print(f\"Results saved to {csv_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Split into validation, test and training data sets\n",
        "def organize_images(csv_file, image_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Organize images into subfolders based on the number of seals and average pixel values.\n",
        "\n",
        "    Args:\n",
        "    - csv_file (str): Path to the CSV file containing image data.\n",
        "    - image_folder (str): Directory containing the images.\n",
        "    - output_folder (str): Directory to save the organized subfolders.\n",
        "    \"\"\"\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Create the main output directories\n",
        "    no_seals_folder = os.path.join(output_folder, 'no_seals')\n",
        "    seals_folder = os.path.join(output_folder, 'seals')\n",
        "    os.makedirs(no_seals_folder, exist_ok=True)\n",
        "    os.makedirs(seals_folder, exist_ok=True)\n",
        "\n",
        "    # Create subfolders for 'no_seals'\n",
        "    ice_folder = os.path.join(no_seals_folder, 'ice')\n",
        "    water_folder = os.path.join(no_seals_folder, 'water')\n",
        "    os.makedirs(ice_folder, exist_ok=True)\n",
        "    os.makedirs(water_folder, exist_ok=True)\n",
        "\n",
        "    # Process each row in the CSV\n",
        "    for index, row in df.iterrows():\n",
        "        image_name = row[0]\n",
        "        seal_count = row[1]\n",
        "        avg_pixel_value = row[2]\n",
        "\n",
        "        # Define the source and destination paths\n",
        "        src_path = os.path.join(image_folder, image_name)\n",
        "\n",
        "        # Determine the destination folder based on seal count and pixel value\n",
        "        if seal_count == 0:\n",
        "            if avg_pixel_value > 20:\n",
        "                dst_folder = ice_folder\n",
        "            else:\n",
        "                dst_folder = water_folder\n",
        "        else:\n",
        "            dst_folder = seals_folder\n",
        "\n",
        "        # Copy the image to the appropriate folder\n",
        "        dst_path = os.path.join(dst_folder, image_name)\n",
        "        shutil.copy(src_path, dst_path)\n",
        "\n",
        "    print(\"Images have been organized into subfolders.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def split_data(input_panchromatic, input_mask, output_path, train_ratio=0.8, val_ratio=0.15, test_ratio=0.05):\n",
        "    assert train_ratio + val_ratio + test_ratio == 1, \"The ratios must sum to 1.\"\n",
        "    def move_files(files, output_subfolder):\n",
        "        for file in files:\n",
        "            filename = os.path.basename(file)\n",
        "            shutil.copy(file, os.path.join(output_subfolder, 'images', filename))\n",
        "            mask_file = file.replace(input_panchromatic, input_mask)\n",
        "            shutil.copy(mask_file, os.path.join(output_subfolder, 'masks', filename))\n",
        "    # Collect and sort images\n",
        "    seals_images = sorted(glob(os.path.join(input_panchromatic, 'seals', '*.tif')))\n",
        "    water_images = sorted(glob(os.path.join(input_panchromatic, 'no_seals', 'water', '*.tif')))\n",
        "    ice_images = sorted(glob(os.path.join(input_panchromatic, 'no_seals', 'ice', '*.tif')))\n",
        "    total_seals = len(seals_images)\n",
        "    half_seals = total_seals // 2\n",
        "\n",
        "    # Ensure water and ice have enough images\n",
        "    water_images = water_images[:half_seals]\n",
        "    ice_images = ice_images[:half_seals]\n",
        "    train_count = int(train_ratio * total_seals)\n",
        "    val_count = int(val_ratio * total_seals)\n",
        "    test_count = total_seals - train_count - val_count\n",
        "\n",
        "    # Split images\n",
        "    train_images = seals_images[:train_count] + water_images[:train_count//2] + ice_images[:train_count//2]\n",
        "    val_images = seals_images[train_count:train_count + val_count] + water_images[train_count//2:train_count//2 + val_count//2] + ice_images[train_count//2:train_count//2 + val_count//2]\n",
        "    test_images = seals_images[train_count + val_count:] + water_images[train_count//2 + val_count//2:] + ice_images[train_count//2 + val_count//2:]\n",
        "\n",
        "    move_files(train_images, os.path.join(output_path, 'train'))\n",
        "    move_files(val_images, os.path.join(output_path, 'val'))\n",
        "    move_files(test_images, os.path.join(output_path, 'test'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o76fmYuGevvL"
      },
      "source": [
        "### Functions for SealNN training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "kttEHLCcd_We"
      },
      "outputs": [],
      "source": [
        "def trans(image, mask):\n",
        "    # Convert to tensor\n",
        "    image = TF.to_tensor(image).float() / 255.0 # get pixel values between 0 and 1 for uint8\n",
        "    mask = TF.to_tensor(mask).float() # Ensure mask is also in float32\n",
        "\n",
        "    # Set a random seed\n",
        "    seed = random.randint(0, 2**32 - 1)\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Apply horizontal flip with 50% probability\n",
        "    if random.random() < 0.5:\n",
        "        image = TF.hflip(image)\n",
        "        mask = TF.hflip(mask)\n",
        "\n",
        "    if image.shape[0] != 1:\n",
        "        image = image[:3, :, :]  # Assumes that first three channels are RGB\n",
        "        mask = mask.repeat(3, 1, 1)\n",
        "        image = TF.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    else:\n",
        "        image = TF.normalize(image, mean=0.445, std=0.269)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def denormalize(image_tensor): #This is for denormalization for visualisation purposes\n",
        "    if image_tensor.shape[0] != 1:\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(image_tensor.device)\n",
        "        std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(image_tensor.device)\n",
        "    else:\n",
        "        mean = torch.tensor([0.5]).view(1, 1, 1).to(image_tensor.device)\n",
        "        std = torch.tensor([0.5]).view(1, 1, 1).to(image_tensor.device)\n",
        "    image_tensor = image_tensor * std + mean\n",
        "    return image_tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Custom dataset to properly import for segmentation\n",
        "def segmentation_dataset(data_path, transform=None):\n",
        "   images_path = os.path.join(data_path, \"images\")\n",
        "   masks_path = os.path.join(data_path, \"masks\")\n",
        "   image_files = os.listdir(images_path)\n",
        "\n",
        "   dataset = []\n",
        "   for img_name in image_files:\n",
        "         image = tifffile.imread(os.path.join(images_path, img_name)) #read .tif file\n",
        "         mask = tifffile.imread(os.path.join(masks_path, img_name[:-4] + '.tif')) #read corresponding mask .tif file\n",
        "\n",
        "         if transform:\n",
        "           image, mask = trans(image, mask)\n",
        "           #mask = transform(mask) #apply transform to both image and corresponding mask\n",
        "\n",
        "         dataset.append((image, mask)) #append the image-mask pair in the dataset\n",
        "\n",
        "   return dataset\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#https://github.com/hsiangyuzhao/Segmentation-Metrics-PyTorch/blob/master/metric.py\n",
        "def metrics(groundtruths, predictions, threshold = 0.5):\n",
        "        output = torch.cat(groundtruths, dim = 0)\n",
        "        target = torch.cat(predictions, dim = 0)\n",
        "        #pred = (all_outputs > threshold).float()\n",
        "\n",
        "        #output = predictions.view(-1, )\n",
        "        #target = groundtruths.view(-1, ).float()\n",
        "\n",
        "        tp = torch.sum(output * target)  # TP\n",
        "        fp = torch.sum(output * (1 - target))  # FP\n",
        "        fn = torch.sum((1 - output) * target)  # FN\n",
        "        tn = torch.sum((1 - output) * (1 - target))  # TN\n",
        "\n",
        "        eps = 1e-7 # Small number to avoid devision by zero\n",
        "\n",
        "        pixel_acc = (tp + tn + eps) / (tp + tn + fp + fn + eps)\n",
        "        dice = (2 * tp + eps) / (2 * tp + fp + fn + eps)\n",
        "        precision = (tp + eps) / (tp + fp + eps)\n",
        "        recall = (tp + eps) / (tp + fn + eps)\n",
        "        specificity = (tn + eps) / (tn + fp + eps)\n",
        "\n",
        "        table = [[\"Pixel Accuracy\", pixel_acc],\n",
        "                 [\"Dice\", dice],\n",
        "                 [\"Precision\", precision],\n",
        "                 [\"Recall\", recall],\n",
        "                 [\"Specificity\", specificity]]\n",
        "\n",
        "        head = [\"Metric\", \"Value\"]\n",
        "\n",
        "        print(tabulate(table, headers=head, tablefmt=\"grid\"))\n",
        "\n",
        "        return pixel_acc, dice, precision, recall, specificity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']\n",
        "\n",
        "\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "alpha = 0.35\n",
        "beta = 0.65\n",
        "# Tversky loss https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch\n",
        "class TverskyLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(TverskyLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1, alpha=alpha, beta=beta):\n",
        "\n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        inputs = F.sigmoid(inputs)\n",
        "\n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        #True Positives, False Positives & False Negatives\n",
        "        TP = (inputs * targets).sum()\n",
        "        FP = ((1-targets) * inputs).sum()\n",
        "        FN = (targets * (1-inputs)).sum()\n",
        "\n",
        "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)\n",
        "\n",
        "        return 1 - Tversky"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nAlB2Z0fx3Q"
      },
      "source": [
        "## Image processing\n",
        "Both panchromatic and multispectral satellite images can be processed in this code. Only panchromatic images are used, and multispectral lines are commented out to save processing time.\n",
        "If multispectral images are processed, make sure the sections with pansharpened images are used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HKyL7G0iDLN"
      },
      "source": [
        "### Define paths and create directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d7_JzYKZMUEY"
      },
      "outputs": [],
      "source": [
        "input_path = os.path.join(project_path, 'data/1_preprocessing/input')\n",
        "os.makedirs(input_path, exist_ok=True)\n",
        "output_path =  os.path.join(project_path, 'data/1_preprocessing/output')\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "panchromatic_path = os.path.join(project_path, 'data/1_preprocessing/input/panchromatic')\n",
        "os.makedirs(panchromatic_path, exist_ok=True)\n",
        "panchromatic = os.path.join(panchromatic_path, '22MAR25134903-P3DS-014983717010_01_P001.tif')\n",
        "panchromatic_reduced_path = os.path.join(project_path, 'data/1_preprocessing/input/panchromatic_reduced')\n",
        "os.makedirs(panchromatic_reduced_path, exist_ok=True)\n",
        "panchromatic_reduced = os.path.join(panchromatic_reduced_path, 'panchromatic_reduced.tif')\n",
        "\n",
        "pansharpened_path = os.path.join(project_path, 'data/1_preprocessing/input/pansharpened')\n",
        "os.makedirs(pansharpened_path, exist_ok=True)\n",
        "pansharpened_reduced_path = os.path.join(project_path, 'data/1_preprocessing/input/pansharpened_reduced')\n",
        "os.makedirs(pansharpened_reduced_path, exist_ok=True)\n",
        "pansharpened_reduced = os.path.join(pansharpened_reduced_path, 'pansharpened_reduced.tif')\n",
        "\n",
        "shapefile_path  = os.path.join(project_path, 'data/1_preprocessing/input/shapefiles')\n",
        "os.makedirs(shapefile_path, exist_ok=True)\n",
        "\n",
        "panchromatic_parts_path = os.path.join(project_path, 'data/1_preprocessing/input/panchromatic_parts')\n",
        "os.makedirs(panchromatic_parts_path, exist_ok=True)\n",
        "pansharpened_parts_path = os.path.join(project_path, 'data/1_preprocessing/input/pansharpened_parts')\n",
        "os.makedirs(pansharpened_parts_path, exist_ok=True)\n",
        "mask_parts_path = os.path.join(project_path, 'data/1_preprocessing/input/mask_parts')\n",
        "os.makedirs(mask_parts_path, exist_ok=True)\n",
        "\n",
        "csv_path = os.path.join(input_path, 'points_within_images.csv')\n",
        "mask_path = os.path.join(input_path, 'raster_mask.tif')\n",
        "\n",
        "output_panchromatic= os.path.join(output_path, 'panchromatic')\n",
        "os.makedirs(output_panchromatic, exist_ok=True)\n",
        "output_pansharpened = os.path.join(output_path, 'pansharpened')\n",
        "os.makedirs(output_pansharpened, exist_ok=True)\n",
        "output_mask = os.path.join(output_path, 'mask')\n",
        "os.makedirs(output_mask, exist_ok=True)\n",
        "\n",
        "# Define paths for deep learning input\n",
        "input_path_deeplearning = os.path.join(project_path, 'data/2_deep_learning')\n",
        "panchromatic_path_dl = os.path.join(input_path_deeplearning, 'panchromatic')\n",
        "pansharpened_path_dl = os.path.join(input_path_deeplearning, 'pansharpened')\n",
        "\n",
        "# Create directories\n",
        "for path in [panchromatic_path_dl, pansharpened_path_dl]:\n",
        "    os.makedirs(os.path.join(path, 'train', 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, 'train', 'masks'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, 'val', 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, 'val', 'masks'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, 'test', 'images'), exist_ok=True)\n",
        "    os.makedirs(os.path.join(path, 'test', 'masks'), exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1Yftx9giJef"
      },
      "source": [
        "### Reduce the resolution and save to a new folder\n",
        "\n",
        "Read the raster image, rescale its pixel values to 8 bits, and save the output in a new folder.\n",
        "The mosaic_rasters combines the RGB raster images into a single mosaic image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "TC_tjP1jbmjJ"
      },
      "outputs": [],
      "source": [
        "# resize_rasters_in_folder(pansharpened_path, pansharpened_reduced_path)\n",
        "reduce_radiometric_resolution(panchromatic, panchromatic_reduced)\n",
        "\n",
        "# mosaic_rasters(pansharpened_reduced_path, pansharpened_reduced)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAShwpKXuHZc"
      },
      "source": [
        "### Create masks from annotated seals and save to a new folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2a1haNHB9bZE"
      },
      "outputs": [],
      "source": [
        "mask_raster_with_polygon(panchromatic_reduced, raster_points_to_polygons(panchromatic_reduced, shapefile_path), mask_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EHTTA0IuYp0"
      },
      "source": [
        "### Split the rasters into smaller images (the image size used in Imagenet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "eFROUVuKMUEm",
        "outputId": "89941a33-9fac-496f-bf10-b2a651d82c85"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-9c6472a70ee8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msplit_and_save_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpanchromatic_reduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpanchromatic_parts_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# split_and_save_raster(pansharpened_reduced, width, height, pansharpened_parts_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msplit_and_save_raster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_parts_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-b618aa944add>\u001b[0m in \u001b[0;36msplit_and_save_raster\u001b[0;34m(input_raster_path, part_width, part_height, output_folder)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetDriverByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GTiff'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0moutput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'part_{i}_{j}.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m             \u001b[0mout_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpart_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGDT_UInt16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Write data to the new dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/osgeo/gdal.py\u001b[0m in \u001b[0;36mCreate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"GDALDatasetShadow *\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m         \u001b[0;34mr\"\"\"Create(Driver self, char const * utf8_path, int xsize, int ysize, int bands=1, GDALDataType eType=GDT_Byte, char ** options=None) -> Dataset\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDriver_Create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mCreateMultiDimensional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"GDALDatasetShadow *\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "width = 224\n",
        "height = 224\n",
        "\n",
        "split_and_save_raster(panchromatic_reduced, width, height, panchromatic_parts_path)\n",
        "# split_and_save_raster(pansharpened_reduced, width, height, pansharpened_parts_path)\n",
        "split_and_save_raster(mask_path, width, height, mask_parts_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yJLTMDUvLd1"
      },
      "source": [
        "### Remove images and masks from a directory if the raster contains zero value pixels.\n",
        "First, remove multispectral images and masks from a directory if their corresponding panchromatic image contains zero value pixels (commented out).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kv00NfgBMUEo"
      },
      "outputs": [],
      "source": [
        "# remove_images_with_zero_panchromatic(pansharpened_parts_path, panchromatic_parts_path, mask_parts_path)\n",
        "\n",
        "remove_zero_raster_mask(panchromatic_parts_path, mask_parts_path)\n",
        "# remove_mulraster_with_zero_values(pansharpened_parts_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqx2NMUevYTL"
      },
      "source": [
        "###  Update mask image values\n",
        "Update the masks based on corresponding panchromatic images, setting mask pixels to 0 where the panchromatic pixel value exceeds the threshold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg10uVXTMUEt"
      },
      "outputs": [],
      "source": [
        "threshold_value = 70\n",
        "update_masks(panchromatic_parts_path, mask_parts_path, threshold_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6Z6xcO7w9eJ"
      },
      "source": [
        "### Organize the images based on the number of seals\n",
        "organize images into subfolders based on the number of seals and the average pixel values specified in a CSV file.\n",
        "Obtain_statistics commented out due to long processing time. If the .csv file exists, do not run.\n",
        "\n",
        "Split the data into training, validation, and test sets based on ratios defined in the function, and organize the images and their corresponding masks into separate folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE_BhCdQMUEv"
      },
      "outputs": [],
      "source": [
        "# ## Only run if .csv file does not exist yet\n",
        "# obtain_statistics(panchromatic_parts_path, shapefile_path, csv_path)\n",
        "\n",
        "organize_images(csv_path, panchromatic_parts_path, output_panchromatic)\n",
        "organize_images(csv_path, mask_parts_path, output_mask)\n",
        "# organize_images(csv_path, pansharpened_parts_path, output_pansharpened)\n",
        "\n",
        "split_data(output_panchromatic, output_mask, panchromatic_path_dl)\n",
        "# split_data(output_pansharpened, output_mask, pansharpened_path_dl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWvrf4W_XsaZ"
      },
      "source": [
        "## Training the SealNN model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2N9OagrySF0"
      },
      "source": [
        "### File paths\n",
        "Define the file paths to training, validation and test data.\n",
        "Choose RGB instead if using multispectral images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prsi-JqipbHa"
      },
      "outputs": [],
      "source": [
        "# Choose RGB or BW\n",
        "col = \"panchromatic\" # BW\n",
        "# col = \"pansharpened\" # RGB\n",
        "\n",
        "train_data_path = \"/content/drive/MyDrive/TheNavySeals/data/\"+ col + \"/train\" #TODO: change to relative file path\n",
        "val_data_path = \"/content/drive/MyDrive/TheNavySeals/data/\"+ col + \"/val\"\n",
        "test_data_path = \"/content/drive/MyDrive/TheNavySeals/data/\"+ col + \"/test\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWHGGr6Fy3sr"
      },
      "source": [
        "### Dataset preparation and creating dataloaders\n",
        "Setting up the training, validation, and testing datasets using the segmentation_dataset function, applies transformations (horizontal flip and normalization for the pretrained Imagenet model), and creating DataLoader objects for batching and shuffling the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3GOKKgAprdi"
      },
      "outputs": [],
      "source": [
        "# Create train and test datasets with augmentation (horizontal flip & normalization)\n",
        "train_dataset = segmentation_dataset(train_data_path, transform=trans)\n",
        "val_dataset = segmentation_dataset(val_data_path, transform=trans)\n",
        "test_dataset = segmentation_dataset(test_data_path, transform=trans)\n",
        "\n",
        "batch_size = 8 #Can be changed later\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# Create train and test data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyIk5TcH0SV7"
      },
      "source": [
        "### Check the data type, mean and std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek34vmuHptNi"
      },
      "outputs": [],
      "source": [
        "image, mask = train_dataset[130]\n",
        "print(image.shape, type(image))\n",
        "print(mask.shape, type(image))\n",
        "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
        "print(f'STD: {torch.std(image)}, Mean: {torch.mean(image)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s5GNHQA0Y2E"
      },
      "source": [
        "### Visualizing an example image and mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAtm0BI1pu1Z"
      },
      "outputs": [],
      "source": [
        "image, mask = train_dataset[125]\n",
        "channels = image.shape[0]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].imshow(denormalize(image).permute(1,2,0), cmap = 'gray')  # Convert from tensor format (C, H, W) to (H, W, C)\n",
        "axes[0].set_title('Image')\n",
        "axes[0].axis('off')\n",
        "axes[1].imshow(mask.permute(1,2,0), cmap = 'gray')  # Convert from tensor format (C, H, W) to (H, W, C)\n",
        "axes[1].set_title('Mask')\n",
        "axes[1].axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f'STD: {torch.std(image)}, Mean: {torch.mean(image)}, Min: {torch.min(image)}, Max: {torch.max(image)}')\n",
        "print(image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8H1e36x0fX9"
      },
      "source": [
        "### Check the GPU colab assigns to you"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwA-Rsq7pwo6"
      },
      "outputs": [],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOMFZhPU0sdB"
      },
      "source": [
        "### U-Net\n",
        "Initializing the pretrained U-Net model using the segmentation_models.pytorch library (smp).\n",
        "Source:https://smp.readthedocs.io/en/latest/models.html#unet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHmYzQ09pyaI"
      },
      "outputs": [],
      "source": [
        "model = smp.Unet(\n",
        "    encoder_name=\"efficientnet-b7\",         # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "    encoder_weights='imagenet',             # imagenet if using pretrained, None is no pretraining\n",
        "    in_channels=channels,                   # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
        "    classes=channels                        # model output channels (number of classes in your dataset)\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5vhYOCZ1Kzn"
      },
      "source": [
        "### The training loop\n",
        "Setting up the training loop with the following parameters:\n",
        "\n",
        "\n",
        "*   Learning rate : 0.003\n",
        "*   Number of epochs : 30\n",
        "*   Loss function : Tversky loss (alpha and beta defined in the function)\n",
        "*   Optimizer : Adam\n",
        "*   Scheduler : ReduceLROnPlateau (factor : 0.1, patience : 5)\n",
        "\n",
        "Plot the training and validation loss at the end.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEMJv_wgp13d"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.003\n",
        "num_epochs = 30\n",
        "\n",
        "criterion = TverskyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
        "\n",
        "# Training and validation loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "best_loss = 10000000\n",
        "best_model = 0\n",
        "best_epoch = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    start_time = time.time() #start time for epoch\n",
        "\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    tr_all_outputs = []\n",
        "    tr_all_masks = []\n",
        "    for image, mask in train_loader:\n",
        "        image, mask = image.to(device, dtype=torch.float), mask.to(device, dtype=torch.float)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(image)\n",
        "        loss = criterion(outputs, mask)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        outputs = torch.sigmoid(outputs)\n",
        "        outputs= outputs.cpu().detach()\n",
        "        tr_all_outputs.append(outputs)\n",
        "        tr_all_masks.append(mask.cpu().detach())\n",
        "        train_loss += loss.item()\n",
        "\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_all_outputs = []\n",
        "    val_all_masks = []\n",
        "    with torch.no_grad():\n",
        "        for image, mask in val_loader:\n",
        "            image, mask = image.to(device, dtype=torch.float), mask.to(device, dtype=torch.float)\n",
        "            outputs = model(image)\n",
        "            loss = criterion(outputs, mask)\n",
        "            outputs = torch.sigmoid(outputs)\n",
        "            outputs= outputs.cpu().detach()\n",
        "            val_all_outputs.append(outputs)\n",
        "            val_all_masks.append(mask.cpu().detach())\n",
        "            val_loss += loss.item()\n",
        "\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "      best_loss = val_loss\n",
        "      best_model = model\n",
        "      best_epoch = epoch+1\n",
        "\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_time = end_time - start_time\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Epoch time: {epoch_time: .2f}s, LR: {get_lr(optimizer)}')\n",
        "print(f\"Best epoch is {best_epoch}, with a validation loss of {best_loss}\")\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Val Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-Pckd9p3-vW"
      },
      "source": [
        "### Evaluate the trained model\n",
        "Show pixel accuracy, dice, precision, recall and specificity to evaluate the model metrics.\n",
        "Plot the precision-recall curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCj_Pe37p7i8"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model and collect outputs and masks\n",
        "best_model.eval()\n",
        "\n",
        "te_all_outputs = []\n",
        "te_all_masks = []\n",
        "\n",
        "for image, mask in test_loader:\n",
        "    image, mask = image.to(device, dtype=torch.float), mask.to(device, dtype=torch.float)\n",
        "    outputs = best_model(image)\n",
        "\n",
        "    outputs = torch.sigmoid(outputs)  # Assuming the output is a logit\n",
        "    outputs = outputs.cpu().detach()\n",
        "\n",
        "    te_all_outputs.append(outputs)\n",
        "    te_all_masks.append(mask.cpu().detach())\n",
        "\n",
        "\n",
        "metrics(te_all_outputs, te_all_masks)\n",
        "\n",
        "te_all_outputs = torch.cat(te_all_outputs).view(-1)\n",
        "te_all_masks = torch.cat(te_all_masks).view(-1)\n",
        "\n",
        "\n",
        "te_all_outputs_np = te_all_outputs.numpy()\n",
        "te_all_masks_np = te_all_masks.numpy()\n",
        "\n",
        "# Calculate precision and recall for different thresholds\n",
        "precision, recall, thresholds = precision_recall_curve(te_all_masks_np, te_all_outputs_np)\n",
        "\n",
        "# Plot precision-recall curve\n",
        "plt.figure()\n",
        "plt.plot(recall, precision, marker=' ')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5G_OhLj4zIv"
      },
      "source": [
        "### Visualize test images\n",
        "Plot all the test images with their corresponding true and predicted mask for visual evaluation.\n",
        "Reduce the number of visualized test data if the number of test images is high.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-aDjPOMp-tG"
      },
      "outputs": [],
      "source": [
        "# Index of the image you want to visualize\n",
        "for i in range(len(test_dataset)):\n",
        "\n",
        "# Set visualization variables\n",
        "  image, mask = test_dataset[i]\n",
        "  image = image.to(device, dtype=torch.float).unsqueeze(0)  # Add batch dimension\n",
        "  mask = mask.to(device, dtype=torch.float).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "  best_model.eval()\n",
        "  with torch.no_grad():\n",
        "    pred = best_model(image)\n",
        "\n",
        "  pred = torch.sigmoid(pred).squeeze(0).cpu().numpy()  # Convert prediction to numpy array\n",
        "  pred_print = (pred == 1).astype(float)\n",
        "\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(6, 2))\n",
        "\n",
        "  image_np = denormalize(image.squeeze()).cpu().numpy()\n",
        "  axes[0].imshow(image_np.transpose(1, 2, 0), cmap = 'gray')  # Use grayscale if single channel\n",
        "  axes[0].set_title('Image')\n",
        "  axes[0].axis('off')\n",
        "\n",
        "  mask_np = mask.squeeze().cpu().numpy()\n",
        "  #print(f'True mask shape for imshow: {mask_np.shape}')\n",
        "  if channels != 1:\n",
        "    axes[1].imshow(mask_np.transpose(1, 2, 0), cmap = 'gray')  # Convert mask to numpy array\n",
        "  else:\n",
        "    axes[1].imshow(mask_np, cmap = 'gray')\n",
        "\n",
        "  axes[1].set_title('True Mask')\n",
        "  axes[1].axis('off')\n",
        "\n",
        "  #print(f'Predicted mask shape for imshow: {pred_print.shape}')\n",
        "  axes[2].imshow(pred_print.transpose(1, 2, 0), cmap = 'gray')  # Use grayscale colormap for binary mask\n",
        "  axes[2].set_title('Predicted Mask')\n",
        "  axes[2].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0C0rXEe3ht1"
      },
      "source": [
        "### Saving the model weigths\n",
        "Save the weights and use them in post-processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnROhknqp4A0"
      },
      "outputs": [],
      "source": [
        "# Run this code if your model is good, you can save the weights to drive:\n",
        "if path.exists(\"/content/drive/MyDrive/TheNavySeals/models\") == False:\n",
        "  os.mkdir(\"/content/drive/MyDrive/TheNavySeals/models\")\n",
        "\n",
        "model_name = \"SealNN\"\n",
        "model_path = \"/content/drive/MyDrive/TheNavySeals/models/\"+ model_name\n",
        "torch.save(best_model, model_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
