{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyPQIniDiaQPXo1CbvWcfybt",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/GeoKauko/TheNavySeals/blob/main/1_Preprocessing_integrated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dyKx_RuY9L7f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6db6180c-58dd-47a9-9346-e2bcd92d503b"
   },
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "## Import libraries\n",
    "import os\n",
    "from osgeo import gdal\n",
    "!pip install rasterio\n",
    "import rasterio\n",
    "from rasterio import windows\n",
    "from rasterio.windows import Window\n",
    "\n",
    "from rasterio.plot import reshape_as_image\n",
    "import rasterio.mask\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import mapping, Point, box, Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from rasterio.features import geometry_mask\n",
    "from shapely.geometry import box\n",
    "from rasterio.features import geometry_mask\n",
    "\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from glob import glob"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## GOOGLE COLAB USERS ONLY \n",
    "## Mount Google Drive for data retrieval\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "\n",
    "project_path = '/content/drive/My Drive/TheNavySeals/'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sfFiemxubfj",
    "outputId": "307a800e-a675-4a28-fd53-6594216e1fcd"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## LOCAL USERS ONLY\n",
    "## Change the path to your project directory\n",
    "\n",
    "os.chdir('D:\\E_2024_P6\\SEAL')\n",
    "\n",
    "project_path = ''"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Define paths and create directories\n",
    "\n",
    "input_path = os.path.join(project_path, 'data/1_preprocessing/input')\n",
    "os.makedirs(input_path, exist_ok=True)\n",
    "output_path =  os.path.join(project_path, 'data/1_preprocessing/output')\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "panchromatic_path = os.path.join(project_path, 'data/1_preprocessing/input/panchromatic')\n",
    "os.makedirs(panchromatic_path, exist_ok=True)\n",
    "panchromatic = os.path.join(panchromatic_path, '22MAR25134903-P3DS-014983717010_01_P001.tif')\n",
    "panchromatic_reduced_path = os.path.join(project_path, 'data/1_preprocessing/input/panchromatic_reduced')\n",
    "os.makedirs(panchromatic_reduced_path, exist_ok=True)\n",
    "panchromatic_reduced = os.path.join(panchromatic_reduced_path, 'panchromatic_reduced.tif')\n",
    "\n",
    "pansharpened_path = os.path.join(project_path, 'data/1_preprocessing/input/pansharpened')\n",
    "os.makedirs(pansharpened_path, exist_ok=True)\n",
    "pansharpened_reduced_path = os.path.join(project_path, 'data/1_preprocessing/input/pansharpened_reduced')\n",
    "os.makedirs(pansharpened_reduced_path, exist_ok=True)\n",
    "pansharpened_reduced = os.path.join(pansharpened_reduced_path, 'pansharpened_reduced.tif')\n",
    "\n",
    "shapefile_path  = os.path.join(project_path, 'data/1_preprocessing/input/shapefiles')\n",
    "os.makedirs(shapefile_path, exist_ok=True)\n",
    "\n",
    "panchromatic_parts_path = os.path.join(project_path, 'data/1_preprocessing/input/panchromatic_parts')\n",
    "os.makedirs(panchromatic_parts_path, exist_ok=True)\n",
    "pansharpened_parts_path = os.path.join(project_path, 'data/1_preprocessing/input/pansharpened_parts')\n",
    "os.makedirs(pansharpened_parts_path, exist_ok=True)\n",
    "mask_parts_path = os.path.join(project_path, 'data/1_preprocessing/input/mask_parts')\n",
    "os.makedirs(mask_parts_path, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(input_path, 'points_within_images.csv')\n",
    "mask_path = os.path.join(input_path, 'raster_mask.tif')\n",
    "\n",
    "output_panchromatic= os.path.join(output_path, 'panchromatic')\n",
    "os.makedirs(output_panchromatic, exist_ok=True)\n",
    "output_pansharpened = os.path.join(output_path, 'pansharpened')\n",
    "os.makedirs(output_pansharpened, exist_ok=True)\n",
    "output_mask = os.path.join(output_path, 'mask')\n",
    "os.makedirs(output_mask, exist_ok=True)\n",
    "\n",
    "# Define paths for deep learning input\n",
    "input_path_deeplearning = 'data/2_deep_learning'\n",
    "panchromatic_path_dl = os.path.join(input_path_deeplearning, 'panchromatic')\n",
    "pansharpened_path_dl = os.path.join(input_path_deeplearning, 'pansharpened')\n",
    " \n",
    "# Create directories\n",
    "for path in [panchromatic_path_dl, pansharpened_path_dl]:\n",
    "    os.makedirs(os.path.join(path, 'train', 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, 'train', 'masks'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, 'val', 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, 'val', 'masks'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, 'test', 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(path, 'test', 'masks'), exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Reduce the radiometric resolution of a raster to 8 bits\n",
    "\n",
    "def reduce_radiometric_resolution(input_path, output_path, input_res=11):\n",
    "    '''\n",
    "    Reduce the radiometric resolution of the input raster and save the output raster.\n",
    "    \n",
    "    Args:\n",
    "    - input_path (string): Path to the input raster.\n",
    "    - output_path (string): Path to the output raster.\n",
    "    - input_res (int): Radiometric resolution of the input raster in bits.\n",
    "    '''\n",
    "    # Ensure the output directory exists\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    with rasterio.open(input_path) as src:\n",
    "        # Read the number of bands\n",
    "        num_bands = src.count\n",
    "\n",
    "        # Initialize an array to store the scaled bands\n",
    "        scaled_arrays = []\n",
    "\n",
    "        for band in range(1, num_bands + 1):\n",
    "            # Read the image band as a numpy array\n",
    "            image_array = src.read(band, masked=True)\n",
    "\n",
    "            # Rescale the pixel values to fit within 8-bit range (0-255)\n",
    "            scaled_array = (image_array / (2**input_res - 1) * 255).astype(np.uint8)\n",
    "\n",
    "            # Append the scaled array to the list\n",
    "            scaled_arrays.append(scaled_array)\n",
    "\n",
    "        # Stack the scaled arrays along the first axis to create a 3D array\n",
    "        scaled_arrays = np.stack(scaled_arrays, axis=0)\n",
    "\n",
    "        # Create a new raster profile with 8-bit pixel depth\n",
    "        profile = src.profile\n",
    "        profile.update(dtype=rasterio.uint8, count=num_bands)\n",
    "\n",
    "        # Write the scaled arrays to a new raster file\n",
    "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "            dst.write(scaled_arrays)\n",
    "\n",
    "def resize_rasters_in_folder(input_folder, output_folder):\n",
    "    '''\n",
    "    Reduces the radiometric resolution of all rasters in a folder and saves the output rasters in the output_folder.\n",
    "    \n",
    "    Args:\n",
    "    - input_folder (string): Path to the input folder.\n",
    "    - output_folder (string): Path to the output folder.\n",
    "    '''\n",
    "    # Iterate over each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "\n",
    "        # Ensure we're only processing files (not subdirectories)\n",
    "        if os.path.isfile(input_path):\n",
    "            output_path = os.path.join(output_folder, filename)\n",
    "            reduce_radiometric_resolution(input_path, output_path)\n",
    "\n",
    "# Example usage\n",
    "resize_rasters_in_folder(pansharpened_path, pansharpened_reduced_path)\n",
    "reduce_radiometric_resolution(panchromatic, panchromatic_reduced)"
   ],
   "metadata": {
    "id": "ccVmVzsg9VQ3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Mosaic pansharpened images\n",
    "\n",
    "def mosaic_rasters(input_folder, output_path):\n",
    "    # List to hold the file paths of the rasters to be merged\n",
    "    input_files = []\n",
    "\n",
    "    # Loop through the folder and add all .tif files to the list\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        print(file_name)\n",
    "        if file_name.endswith('.TIF'):\n",
    "            input_files.append(os.path.join(input_folder, file_name))\n",
    "\n",
    "    # Check if we have any input files\n",
    "    if not input_files:\n",
    "        raise FileNotFoundError(\"No .tif files found in the specified folder.\")\n",
    "\n",
    "    # Open the input files\n",
    "    src_files_to_mosaic = []\n",
    "    for file in input_files:\n",
    "        src = gdal.Open(file)\n",
    "        if src:\n",
    "            src_files_to_mosaic.append(src)\n",
    "        else:\n",
    "            print(f\"Failed to open {file}\")\n",
    "\n",
    "    # Create a virtual raster from the input files\n",
    "    vrt = gdal.BuildVRT('temporary.vrt', src_files_to_mosaic)\n",
    "\n",
    "    # Write the virtual raster to a new file\n",
    "    gdal.Translate(output_path, vrt)\n",
    "\n",
    "    # Cleanup\n",
    "    vrt = None\n",
    "    for src in src_files_to_mosaic:\n",
    "        src = None\n",
    "\n",
    "    print(f\"Mosaic raster saved as {output_path}\")\n",
    "\n",
    "mosaic_rasters(pansharpened_reduced_path, pansharpened_reduced)"
   ],
   "metadata": {
    "id": "ACgtGPRN9VM6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d7c9a647-e26f-4d9e-baee-40062333f966"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Mask raster\n",
    "\n",
    "def create_polygon_from_pixels(row, col, transform):\n",
    "    \"\"\"\n",
    "    Create a polygon from a center pixel (row, col) and its 24 surrounding pixels (5x5 block).\n",
    "    \"\"\"\n",
    "    # Calculate the coordinates of the top-left corner of the top-left pixel\n",
    "    top_left_x = transform[0] + (col - 2) * transform[1] + (row - 2) * transform[2]\n",
    "    top_left_y = transform[3] + (col - 2) * transform[4] + (row - 2) * transform[5]\n",
    "\n",
    "    # Pixel dimensions\n",
    "    pixel_width = abs(transform[1])\n",
    "    pixel_height = abs(transform[5])\n",
    "\n",
    "    # Calculate the coordinates for the 5x5 block of pixels\n",
    "    polygon_coords = [\n",
    "        (top_left_x, top_left_y),\n",
    "        (top_left_x + 5 * pixel_width, top_left_y),\n",
    "        (top_left_x + 5 * pixel_width, top_left_y - 5 * pixel_height),\n",
    "        (top_left_x, top_left_y - 5 * pixel_height),\n",
    "        (top_left_x, top_left_y)\n",
    "    ]\n",
    "\n",
    "    return Polygon(polygon_coords)\n",
    "\n",
    "def raster_points_to_polygons(raster_path, shapefile_path):\n",
    "    # Read raster data\n",
    "    raster_dataset = gdal.Open(raster_path)\n",
    "    raster_geotransform = raster_dataset.GetGeoTransform()\n",
    "\n",
    "    # Read shapefile\n",
    "    shapefile_gdf = gpd.read_file(shapefile_path)\n",
    "    shape_crs = shapefile_gdf.crs\n",
    "\n",
    "    polygons = []\n",
    "    for point in shapefile_gdf.geometry:\n",
    "        # Convert point coordinates to raster coordinates\n",
    "        x, y = point.x, point.y\n",
    "        col = int((x - raster_geotransform[0]) / raster_geotransform[1])\n",
    "        row = int((y - raster_geotransform[3]) / raster_geotransform[5])\n",
    "\n",
    "        # Create polygon around the pixel and its 24 surrounding pixels\n",
    "        polygon = create_polygon_from_pixels(row, col, raster_geotransform)\n",
    "        polygons.append(polygon)\n",
    "\n",
    "    result_gdf = gpd.GeoDataFrame(geometry=polygons, crs=shape_crs)\n",
    "\n",
    "    return result_gdf\n",
    "\n",
    "def mask_raster_with_polygon(input_raster_path, polygons, output_raster_path, value=1):\n",
    "    \"\"\"\n",
    "    Create a copy of a raster, set all its values to 0, overlay it with a polygon shapefile,\n",
    "    and set all pixels underneath polygons to a specified value.\n",
    "\n",
    "    Args:\n",
    "    - input_raster_path (str): Path to the input raster.\n",
    "    - polygons (gdf): GeoDataFrame with the polygons of the mask.\n",
    "    - output_raster_path (str): Path to save the masked raster.\n",
    "    - value (int, optional): Value to set for pixels underneath polygons. Defaults to 1.\n",
    "    \"\"\"\n",
    "    # Open the input raster for reading\n",
    "    with rasterio.open(input_raster_path) as src:\n",
    "        # Read raster data\n",
    "        raster_data = src.read(1)\n",
    "        # Get metadata\n",
    "        meta = src.meta\n",
    "\n",
    "    # Set all values to 0\n",
    "    raster_data.fill(0)\n",
    "\n",
    "    # Create mask from polygons\n",
    "    mask = geometry_mask(polygons.geometry, out_shape=raster_data.shape, transform=src.transform, invert=True)\n",
    "\n",
    "    # Set pixels underneath polygons to the specified value\n",
    "    raster_data[mask] = value\n",
    "\n",
    "    # Save the masked raster\n",
    "    with rasterio.open(output_raster_path, 'w', **meta) as dst:\n",
    "        dst.write(raster_data, 1)\n",
    "\n",
    "mask_raster_with_polygon(panchromatic_reduced, raster_points_to_polygons(panchromatic_reduced, shapefile_path), mask_path)"
   ],
   "metadata": {
    "id": "2a1haNHB9bZE"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Tile raster and mask to 224x224 px\n",
    "\n",
    "def split_and_save_raster(input_raster_path, part_width, part_height, output_folder):\n",
    "    '''\n",
    "    Split a raster into multiple tiles of length part_width and height part_height, and save them in output_folder.\n",
    "    \n",
    "    Args:\n",
    "    - input_raster_path: path to the input raster.\n",
    "    - part_width (int): Width of each tile.\n",
    "    - part_height (int): Height of each tile.\n",
    "    - output_folder (str): Directory to save the rasters.\n",
    "    '''\n",
    "    # Open the raster\n",
    "    dataset = gdal.Open(input_raster_path)\n",
    "    \n",
    "    # Get raster dimensions\n",
    "    width = dataset.RasterXSize\n",
    "    height = dataset.RasterYSize\n",
    "\n",
    "    # Calculate the number of parts\n",
    "    num_parts_x = width // part_width\n",
    "    num_parts_y = height // part_height\n",
    "\n",
    "    # Get the number of bands\n",
    "    bands = dataset.RasterCount\n",
    "\n",
    "    # Split the raster and save\n",
    "    for i in range(num_parts_x):\n",
    "        for j in range(num_parts_y):\n",
    "            x_offset = i * part_width\n",
    "            y_offset = j * part_height\n",
    "\n",
    "            # Read the split region\n",
    "            part = dataset.ReadAsArray(x_offset, y_offset, part_width, part_height)\n",
    "\n",
    "            # Expand dimensions if there's only one band\n",
    "            if bands == 1:\n",
    "               part = np.expand_dims(part, axis=0)\n",
    "\n",
    "            # Create a new GDAL dataset to save the split part\n",
    "            driver = gdal.GetDriverByName('GTiff')\n",
    "            output_path = os.path.join(output_folder, f'part_{i}_{j}.tif')\n",
    "            out_dataset = driver.Create(output_path, part_width, part_height, bands, gdal.GDT_UInt16)\n",
    "\n",
    "            # Write data to the new dataset\n",
    "            for band in range(bands):\n",
    "                out_band = out_dataset.GetRasterBand(band + 1)\n",
    "                out_band.WriteArray(part[band])\n",
    "\n",
    "            # Set georeference and projection\n",
    "            geo_transform = list(dataset.GetGeoTransform())\n",
    "            geo_transform[0] += x_offset * geo_transform[1]\n",
    "            geo_transform[3] += y_offset * geo_transform[5]\n",
    "            out_dataset.SetGeoTransform(tuple(geo_transform))\n",
    "            out_dataset.SetProjection(dataset.GetProjection())\n",
    "\n",
    "            # Save and close\n",
    "            out_dataset.FlushCache()\n",
    "            del out_dataset\n",
    "\n",
    "    # Close the original dataset\n",
    "    del dataset\n",
    "\n",
    "width = 224\n",
    "height = 224\n",
    "\n",
    "split_and_save_raster(panchromatic_reduced, width, height, panchromatic_parts_path)\n",
    "split_and_save_raster(pansharpened_reduced, width, height, pansharpened_parts_path)\n",
    "split_and_save_raster(mask_path, width, height, mask_parts_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Remove images and masks with no data values\n",
    "\n",
    "def contains_zero(input_raster_path):\n",
    "    \"\"\"\n",
    "    Check if a single band raster has a zero value pixel. \n",
    "    Args:\n",
    "    - input_raster_path (str): Path to the input raster.\n",
    "    Returns:\n",
    "    - bool: True if the raster contains at least one zero value pixel, False otherwise.\n",
    "    \"\"\"\n",
    "    with rasterio.open(input_raster_path) as src:\n",
    "        # Read the image as a numpy array\n",
    "        raster_array = src.read(1)\n",
    "        # Check if the array contains any zero values\n",
    "        return (raster_array == 0).any()\n",
    " \n",
    "def remove_images_with_zero_panchromatic(directory, panchromatic_directory, mask_directory):\n",
    "    \"\"\"\n",
    "    Removes all images from a directory that contain a zero value pixel in their corresponding panchromatic image.\n",
    "    Also removes images with the same name from the mask directory.\n",
    "    Args:\n",
    "    - directory (str): Path to the directory containing the images to validate (pansharpened).\n",
    "    - panchromatic_directory (str): Path to the directory containing the panchromatic images with the same name.\n",
    "    - mask_directory (str): Path to the directory containing the mask images with the same name.\n",
    "    \"\"\"\n",
    " \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(('.tif', '.tiff')):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            panchromatic_path = os.path.join(panchromatic_directory, filename)\n",
    "            if contains_zero(panchromatic_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"Removed image: {file_path}\")\n",
    " \n",
    "                # Remove the mask image with the same name\n",
    "                mask_path = os.path.join(mask_directory, filename)\n",
    "                if os.path.exists(mask_path):\n",
    "                    os.remove(mask_path)\n",
    "                    print(f\"Removed mask: {mask_path}\")\n",
    " \n",
    " \n",
    "                # Remove the pansharpened image with the same name\n",
    "                panchromatic_path = os.path.join(panchromatic_directory, filename)\n",
    "                if os.path.exists(panchromatic_path):\n",
    "                    os.remove(panchromatic_path)\n",
    "                    print(f\"Removed mask: {panchromatic_path}\")\n",
    " \n",
    "# Remove pansharpened images and corresponding masks based on zero values in corresponding panchromatic images\n",
    "remove_images_with_zero_panchromatic(pansharpened_parts_path, panchromatic_parts_path, mask_parts_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ## Remove images and masks with no data values\n",
    "# \n",
    "# def contains_zero(input_raster_path):\n",
    "#     \"\"\"\n",
    "#     Check if a single band raster has a zero value pixel. \n",
    "#     \n",
    "#     Args:\n",
    "#     - input_raster_path (str): Path to the input raster.\n",
    "#     \n",
    "#     Returns:\n",
    "#     - bool: True if the raster contains at least one zero value pixel, False otherwise.\n",
    "#     \"\"\"\n",
    "#     with rasterio.open(input_raster_path) as src:\n",
    "#         # Read the image as a numpy array\n",
    "#         raster_array = src.read(1)\n",
    "#         # Check if the array contains any zero values\n",
    "#         return (raster_array == 0).any()\n",
    "# \n",
    "# # Potentially this one can be used for multiple bands, but I have yet to test it\n",
    "# def contains_zero_multiband(image_path):\n",
    "#     \"\"\"\n",
    "#     Check if an image has a zero value pixel in any of its bands.\n",
    "#     \"\"\"\n",
    "#     with rasterio.open(image_path) as src:\n",
    "#         # Iterate through each band\n",
    "#         for band in range(1, src.count + 1):\n",
    "#             # Read the current band as a numpy array\n",
    "#             image_array = src.read(band)\n",
    "#             # Check if the array contains any zero values\n",
    "#             if (image_array == 0).any():\n",
    "#                 return True\n",
    "#     return False\n",
    "# \n",
    "# def remove_mulraster_with_zero_values(directory):\n",
    "#     \"\"\"\n",
    "#     Removes all rasters from a directory that contain a zero value pixel.\n",
    "# \n",
    "#     Args:\n",
    "#     - directory (str): Path to the directory containing the images to validate.\n",
    "#     \"\"\"\n",
    "#     for filename in os.listdir(directory):\n",
    "#         if filename.endswith(('.tif', '.tiff')):  \n",
    "#             file_path = os.path.join(directory, filename)\n",
    "#             if contains_zero_multiband(file_path):\n",
    "#                 os.remove(file_path)\n",
    "#                 #print(f\"Removed raster: {file_path}\")\n",
    "#                 \n",
    "# def remove_zero_raster_mask(directory, mask_directory):\n",
    "#     \"\"\"\n",
    "#     Removes all rasters from a directory that contain a zero value pixel.\n",
    "#     Also removes rasters with the same name from the mask directory.\n",
    "#     \n",
    "#     Args:\n",
    "#     - directory (str): Path to the directory containing the rasters to validate.\n",
    "#     - mask_directory (str): Name of the folder containing the mask rasters with the same name.\n",
    "#     \"\"\"\n",
    "# \n",
    "#     for filename in os.listdir(directory):\n",
    "#         if filename.endswith(('.tif', '.tiff')):\n",
    "#             file_path = os.path.join(directory, filename)\n",
    "#             if contains_zero(file_path):\n",
    "#                 os.remove(file_path)\n",
    "#                 # print(f\"Removed image: {file_path}\")\n",
    "# \n",
    "#                 # Remove the image with the same name from the similar folder\n",
    "#                 mask_path = os.path.join(mask_directory, filename)\n",
    "#                 if os.path.exists(mask_path):\n",
    "#                     os.remove(mask_path)\n",
    "#                     # print(f\"Removed similar image: {mask_path}\")\n",
    "#                     \n",
    "# remove_zero_raster_mask(panchromatic_parts_path, mask_parts_path)\n",
    "# remove_mulraster_with_zero_values(pansharpened_parts_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Clip the raster masks to remove pixels above a certain threshold to more accurately represent the seal shape (Pan only)\n",
    "\n",
    "def update_masks(panchromatic_parts_path, mask_parts_path, threshold_value):\n",
    "    \"\"\"\n",
    "    Updates mask images based on corresponding panchromatic images. Specifically, for each mask,\n",
    "    all pixels with a value of 1 that correspond to pixels in the panchromatic image with a value above the \n",
    "    specified threshold are set to 0 in the new mask.\n",
    "\n",
    "    Args:\n",
    "    - panchromatic_parts_path (str): The directory path containing the panchromatic images.\n",
    "    - mask_parts_path (str): The directory path containing the mask images.\n",
    "    - threshold_value (int): The threshold value for the panchromatic image pixels. Pixels in the mask with a value of 1 and corresponding panchromatic image pixels above this threshold will be set to 0 in the new mask.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # List all mask files in the specified directory\n",
    "    mask_files = [f for f in os.listdir(mask_parts_path) if f.endswith('.tif')]\n",
    "    \n",
    "    for mask_file in mask_files:\n",
    "        # Construct the full file paths for the mask and corresponding panchromatic image\n",
    "        mask_path = os.path.join(mask_parts_path, mask_file)\n",
    "        image_path = os.path.join(panchromatic_parts_path, mask_file)\n",
    "        \n",
    "        # Read the panchromatic image\n",
    "        with rasterio.open(image_path) as img:\n",
    "            image_data = img.read(1)\n",
    "        \n",
    "        # Read the mask image\n",
    "        with rasterio.open(mask_path) as mask:\n",
    "            mask_data = mask.read(1)\n",
    "            mask_meta = mask.meta\n",
    "        \n",
    "        # Update the mask data based on the condition\n",
    "        new_mask_data = np.where((mask_data == 1) & (image_data > threshold_value), 0, mask_data)\n",
    "        \n",
    "        # Save the new mask data overwriting the old mask\n",
    "        with rasterio.open(mask_path, 'w', **mask_meta) as mask:\n",
    "            mask.write(new_mask_data, 1)\n",
    "\n",
    "# Usage example\n",
    "threshold_value = 70\n",
    "update_masks(panchromatic_parts_path, mask_parts_path, threshold_value)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Don't Run\n",
    "def obtain_statistic(image_path, shapefile_path):\n",
    "    '''\n",
    "    Count the points that are within the bounds of an image and calculate the average pixel value.\n",
    "    Args:\n",
    "    - image_path (str): Path to the input raster.\n",
    "    - shapefile_path (str): Path to the shapefile containing points.\n",
    "    Returns:\n",
    "    - num_points (int): Number of points within the image bounds.\n",
    "    - avg_pixel_value (float): Average pixel value of the image.\n",
    "    '''\n",
    "    with rasterio.open(image_path) as src:\n",
    "        image_bounds = src.bounds\n",
    "        image_box = box(image_bounds.left, image_bounds.bottom, image_bounds.right, image_bounds.top)\n",
    "        # Read the CRS from the image\n",
    "        image_crs = src.crs\n",
    "        # Calculate the average pixel value\n",
    "        image_data = src.read(1)  # Read the first band\n",
    "        avg_pixel_value = np.mean(image_data)\n",
    "    shapefile = gpd.read_file(shapefile_path)\n",
    " \n",
    "    shapefile['within_image'] = shapefile.apply(lambda row: image_box.contains(Point(row.geometry.x, row.geometry.y)), axis=1)\n",
    "    points_within_image = shapefile[shapefile['within_image']]\n",
    " \n",
    "    return len(points_within_image), avg_pixel_value\n",
    " \n",
    "def obtain_statistics(image_dir, shapefile_path, csv_path):\n",
    "    # List to store results\n",
    "    results = []\n",
    " \n",
    "    # Iterate through all images in the directory\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        if image_name.endswith('.tif'):\n",
    "            image_path = os.path.join(image_dir, image_name)\n",
    "            num_points, avg_pixel_value = obtain_statistic(image_path, shapefile_path)\n",
    "            results.append({'image_name': image_name, 'num_points': num_points, 'avg_pixel_value': avg_pixel_value})\n",
    "            print(f'appended image {image_name}')\n",
    "    # Convert results to DataFrame and save as CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    " \n",
    "    print(f\"Results saved to {csv_path}\")\n",
    " \n",
    "# Run the main function\n",
    "obtain_statistics(panchromatic_parts_path, shapefile_path, csv_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Split into validation, test and training data sets\n",
    "def organize_images(csv_file, image_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Organize images into subfolders based on the number of seals and average pixel values.\n",
    "    \n",
    "    Args:\n",
    "    - csv_file (str): Path to the CSV file containing image data.\n",
    "    - image_folder (str): Directory containing the images.\n",
    "    - output_folder (str): Directory to save the organized subfolders.\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Create the main output directories\n",
    "    no_seals_folder = os.path.join(output_folder, 'no_seals')\n",
    "    seals_folder = os.path.join(output_folder, 'seals')\n",
    "    os.makedirs(no_seals_folder, exist_ok=True)\n",
    "    os.makedirs(seals_folder, exist_ok=True)\n",
    "    \n",
    "    # Create subfolders for 'no_seals'\n",
    "    ice_folder = os.path.join(no_seals_folder, 'ice')\n",
    "    water_folder = os.path.join(no_seals_folder, 'water')\n",
    "    os.makedirs(ice_folder, exist_ok=True)\n",
    "    os.makedirs(water_folder, exist_ok=True)\n",
    "    \n",
    "    # Process each row in the CSV\n",
    "    for index, row in df.iterrows():\n",
    "        image_name = row[0]\n",
    "        seal_count = row[1]\n",
    "        avg_pixel_value = row[2]\n",
    "        \n",
    "        # Define the source and destination paths\n",
    "        src_path = os.path.join(image_folder, image_name)\n",
    "        \n",
    "        # Determine the destination folder based on seal count and pixel value\n",
    "        if seal_count == 0:\n",
    "            if avg_pixel_value > 20:\n",
    "                dst_folder = ice_folder\n",
    "            else:\n",
    "                dst_folder = water_folder\n",
    "        else:\n",
    "            dst_folder = seals_folder\n",
    "        \n",
    "        # Copy the image to the appropriate folder\n",
    "        dst_path = os.path.join(dst_folder, image_name)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    \n",
    "    print(\"Images have been organized into subfolders.\")\n",
    "\n",
    "organize_images(csv_path, panchromatic_parts_path, output_panchromatic)\n",
    "organize_images(csv_path, mask_parts_path, output_mask)\n",
    "organize_images(csv_path, pansharpened_parts_path, output_pansharpened)\n",
    "\n",
    "def split_data(input_panchromatic, input_mask, output_path, train_ratio=0.8, val_ratio=0.15, test_ratio=0.05):\n",
    "    assert train_ratio + val_ratio + test_ratio == 1, \"The ratios must sum to 1.\"\n",
    "    def move_files(files, output_subfolder):\n",
    "        for file in files:\n",
    "            filename = os.path.basename(file)\n",
    "            shutil.copy(file, os.path.join(output_subfolder, 'images', filename))\n",
    "            mask_file = file.replace(input_panchromatic, input_mask)\n",
    "            shutil.copy(mask_file, os.path.join(output_subfolder, 'masks', filename))\n",
    "    # Collect and sort images\n",
    "    seals_images = sorted(glob(os.path.join(input_panchromatic, 'seals', '*.tif')))\n",
    "    water_images = sorted(glob(os.path.join(input_panchromatic, 'no_seals', 'water', '*.tif')))\n",
    "    ice_images = sorted(glob(os.path.join(input_panchromatic, 'no_seals', 'ice', '*.tif')))\n",
    "    total_seals = len(seals_images)\n",
    "    half_seals = total_seals // 2\n",
    " \n",
    "    # Ensure water and ice have enough images\n",
    "    water_images = water_images[:half_seals]\n",
    "    ice_images = ice_images[:half_seals]\n",
    "    train_count = int(train_ratio * total_seals)\n",
    "    val_count = int(val_ratio * total_seals)\n",
    "    test_count = total_seals - train_count - val_count\n",
    " \n",
    "    # Split images\n",
    "    train_images = seals_images[:train_count] + water_images[:train_count//2] + ice_images[:train_count//2]\n",
    "    val_images = seals_images[train_count:train_count + val_count] + water_images[train_count//2:train_count//2 + val_count//2] + ice_images[train_count//2:train_count//2 + val_count//2]\n",
    "    test_images = seals_images[train_count + val_count:] + water_images[train_count//2 + val_count//2:] + ice_images[train_count//2 + val_count//2:]\n",
    "\n",
    "    move_files(train_images, os.path.join(output_path, 'train'))\n",
    "    move_files(val_images, os.path.join(output_path, 'val'))\n",
    "    move_files(test_images, os.path.join(output_path, 'test'))\n",
    "\n",
    "split_data(output_panchromatic, output_mask, panchromatic_path_dl)\n",
    "split_data(output_pansharpened, output_mask, pansharpened_path_dl)"
   ],
   "metadata": {
    "id": "xMNiYzk19fD5"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
