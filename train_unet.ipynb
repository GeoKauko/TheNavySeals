{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWu4mAZ5YqfTRNIgvjdjwz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeoKauko/TheNavySeals/blob/main/train_unet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install segmentation-models-pytorch -q\n",
        "!pip install ttach -q\n",
        "!pip install wandb -q\n",
        "!pip install utils -q"
      ],
      "metadata": {
        "id": "mJhfhaFiKqaQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "import uuid\n",
        "from pathlib import Path\n",
        "from typing import Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import segmentation_models_pytorch as smp\n",
        "import torchvision\n",
        "import ttach.aliases\n",
        "import wandb\n",
        "from torch import optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "sys.path.insert(0, \"../\")\n",
        "\n",
        "from utils.models.model_factory import get_semantic_segmentation_model\n",
        "from utils.models.transunet import TransUnet\n",
        "from utils.models.tta_wrapper import SegmentationRegTTAWrapper\n",
        "from utils.training.utility import seed_all\n",
        "from utils.data_processing import provider, inv_normalize\n",
        "from utils.loss_functions import SoftDiceLoss, FocalLoss, DiceLoss, MixedLoss\n",
        "from utils.evaluation.eval_unet import validate_unet, test_unet\n",
        "\n",
        "dir_checkpoint = Path(\"./checkpoints/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "MeEpzjAnKHTQ",
        "outputId": "cff5493a-e9cf-4947-afcf-281acf0553bb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils.models'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7c3541848819>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"../\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_semantic_segmentation_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransunet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransUnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtta_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSegmentationRegTTAWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.models'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_args():\n",
        "    parser = argparse.ArgumentParser(\n",
        "        description=\"Train the UNet on images and target masks\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--training-dir\",\n",
        "        \"-tr\",\n",
        "        dest=\"training_dir\",\n",
        "        type=str,\n",
        "        default=\"training_set\",\n",
        "        help=\"Path to training set\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--alpha-count\",\n",
        "        \"-a\",\n",
        "        dest=\"alpha_count\",\n",
        "        type=float,\n",
        "        default=0.5,\n",
        "        help=\"Relative weight for count loss\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--uniform-group-weights\",\n",
        "        \"-u\",\n",
        "        dest=\"uniform_group_weights\",\n",
        "        type=int,\n",
        "        default=False,\n",
        "        help=\"Use weighted sampler to have uniform group sizes on positive samples?\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--epochs\", \"-e\", metavar=\"E\", type=int, default=5, help=\"Number of epochs\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--batch-size\",\n",
        "        \"-b\",\n",
        "        dest=\"batch_size\",\n",
        "        metavar=\"B\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Batch size for dataloader, multiplied by 2 for validation\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--patch-size\",\n",
        "        \"-ps\",\n",
        "        dest=\"patch_size\",\n",
        "        type=int,\n",
        "        default=256,\n",
        "        help=\"Patch size for input tiles\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--learning-rate\",\n",
        "        \"-l\",\n",
        "        metavar=\"LR\",\n",
        "        type=float,\n",
        "        default=1e-5,\n",
        "        help=\"Learning rate\",\n",
        "        dest=\"lr\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--load\", \"-f\", type=str, default=False, help=\"Load model from a .pth file\"\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--neg-to-pos-ratio\",\n",
        "        \"-n\",\n",
        "        dest=\"neg_to_pos_ratio\",\n",
        "        type=float,\n",
        "        default=1.0,\n",
        "        help=\"Scale between number of negative and positive samples in train dataloader\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--patience\",\n",
        "        \"-p\",\n",
        "        type=int,\n",
        "        default=3,\n",
        "        help=\"Number of non-improving epochs until \" \"learning rate is decreased\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--augmentation-mode\",\n",
        "        \"-g\",\n",
        "        type=str,\n",
        "        dest=\"augmentation_mode\",\n",
        "        default=\"simple\",\n",
        "        choices=[\"simple\", \"complex\"],\n",
        "        help=\"Augmentation mode\",\n",
        "    )\n",
        "    parser.add_argument(\"--amp\", \"-m\", type=int, default=0, help=\"Use mixed precision\")\n",
        "    parser.add_argument(\n",
        "        \"--criterion-mask\",\n",
        "        \"-c\",\n",
        "        type=str,\n",
        "        default=\"Dice\",\n",
        "        choices=[\"Dice\", \"SoftDice\", \"Focal\", \"Mixed\"],\n",
        "        dest=\"criterion_mask\",\n",
        "        help=\"Loss function for training U-Net masks\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--num-workers\",\n",
        "        \"-w\",\n",
        "        dest=\"num_workers\",\n",
        "        type=int,\n",
        "        default=1,\n",
        "        help=\"Number of workers for dataloaders\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--val-rounds-per-epoch\",\n",
        "        \"-v\",\n",
        "        dest=\"val_rounds_per_epoch\",\n",
        "        type=int,\n",
        "        default=3,\n",
        "        help=\"Number of validation rounds per epoch\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--data-parallel\",\n",
        "        \"-dp\",\n",
        "        dest=\"data_parallel\",\n",
        "        default=False,\n",
        "        help=\"Use data parallelism? (multi-gpu)\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--test-gdf\",\n",
        "        \"-tgt\",\n",
        "        dest=\"test_gdf\",\n",
        "        default=\"../shapefiles/seal-points-test-consensus.shp\",\n",
        "        help=\"Path to shapefile with test GT points\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--model-architecture\",\n",
        "        \"-ma\",\n",
        "        dest=\"model_architecture\",\n",
        "        type=str,\n",
        "        default=\"UnetResnet34\",\n",
        "        choices=[\n",
        "            \"UnetResnet34\",\n",
        "            \"UnetEfficientNet-b0\",\n",
        "            \"UnetEfficientNet-b1\",\n",
        "            \"UnetEfficientNet-b2\",\n",
        "            \"UnetEfficientNet-b3\",\n",
        "        ],\n",
        "        help=\"Model architecture name\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--dropout-regression\",\n",
        "        \"-dr\",\n",
        "        dest=\"dropout_regression\",\n",
        "        type=float,\n",
        "        default=0.0,\n",
        "        help=\"Dropout for regression head\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--tta\",\n",
        "        \"-t\",\n",
        "        dest=\"tta\",\n",
        "        type=int,\n",
        "        default=0.0,\n",
        "        help=\"Use test-time-augmentation?\",\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        \"--min-val-f1-test\",\n",
        "        \"-mf\",\n",
        "        dest=\"min_val_f1_test\",\n",
        "        type=float,\n",
        "        default=0.7,\n",
        "        help=\"Runs with best validation f1-score below this value will terminate early without \"\n",
        "        \"a testing phase.\",\n",
        "    )\n",
        "    return parser.parse_args()\n",
        "\n"
      ],
      "metadata": {
        "id": "ajaObiIRKPVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wa2Ypn7XIer6"
      },
      "outputs": [],
      "source": [
        "def train_net(\n",
        "    net: Union[nn.DataParallel, smp.Unet, TransUnet],\n",
        "    device: torch.device,\n",
        "    experiment_id: str,\n",
        "    training_dir: str = \"training_set\",\n",
        "    alpha_count: float = 0.5,\n",
        "    epochs: int = 5,\n",
        "    batch_size: int = 1,\n",
        "    patch_size: int = 256,\n",
        "    num_workers: int = 1,\n",
        "    learning_rate: float = 1e-5,\n",
        "    criterion_mask: nn.Module = SoftDiceLoss(),\n",
        "    patience: int = 3,\n",
        "    decay_factor: float = 0.5,\n",
        "    criterion_count: nn.Module = nn.SmoothL1Loss(),\n",
        "    neg_to_pos_ratio: float = 1.0,\n",
        "    val_rounds_per_epoch: int = 3,\n",
        "    augmentation_mode: str = \"simple\",\n",
        "    uniform_group_weights: bool = False,\n",
        "    save_checkpoint: bool = False,\n",
        "    amp: bool = False,\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Training loop for SealNet2.0, supports several options for hyperparameter tuning. Stores\n",
        "    training statistics in wandb project.\n",
        "\n",
        "    :param net: Unet from smp with a regression head\n",
        "    :param device: device for running training loop\n",
        "    :param experiment_id: experiment id for wandb\n",
        "    :param alpha_count: relative weight for regression loss [0, 1]\n",
        "    :param epochs: number of epochs to run training for\n",
        "    :param batch_size: batch size for training dataloader (multiplied x2 for val and test)\n",
        "    :param patch_size: patch size for training images\n",
        "    :param num_workers: number of workers for train/val dataloaders\n",
        "    :param learning_rate: learning rate\n",
        "    :param criterion_mask: criterion for segmentation loss\n",
        "    :param patience: number of rounds without improvement until reducing learning rate\n",
        "    :param decay_factor: multiplier for reducing learning rate\n",
        "    :param criterion_count: criterion for regression loss\n",
        "    :param neg_to_pos_ratio: ratio of negative to positive images on training batches\n",
        "    :param val_rounds_per_epoch: number of validation rounds within one epoch\n",
        "    :param augmentation_mode: data augmentation mode E{simple, complex}\n",
        "    :param uniform_group_weights: use uniform group weights on training batches?\n",
        "    :param save_checkpoint: save model checkpoints?\n",
        "    :param amp: use auto mixed-precision? (make sure your GPU supports amp)\n",
        "\n",
        "    :returns best validation f-1 score\n",
        "    \"\"\"\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = provider(\n",
        "        data_folder=f\"../{training_dir}\",\n",
        "        annotation_ds=f\"../{training_dir}/annotations_df.csv\",\n",
        "        num_workers=num_workers,\n",
        "        augmentation_mode=augmentation_mode,\n",
        "        uniform_group_weights=uniform_group_weights,\n",
        "        batch_size=batch_size,\n",
        "        neg_to_pos_ratio=neg_to_pos_ratio,\n",
        "        phase=\"training\",\n",
        "        patch_size=patch_size,\n",
        "    )\n",
        "    val_loader = provider(\n",
        "        data_folder=f\"../{training_dir}\",\n",
        "        annotation_ds=f\"../{training_dir}/annotations_df.csv\",\n",
        "        num_workers=num_workers,\n",
        "        augmentation_mode=augmentation_mode,\n",
        "        batch_size=batch_size * 2,\n",
        "        phase=\"validation\",\n",
        "        patch_size=patch_size,\n",
        "    )\n",
        "\n",
        "    n_train = len(train_loader) * batch_size\n",
        "    n_val = len(val_loader) * batch_size * 2\n",
        "\n",
        "    # Initialize logging\n",
        "    experiment = wandb.init(\n",
        "        project=\"SealNet2.0\",\n",
        "        resume=\"allow\",\n",
        "        anonymous=\"allow\",\n",
        "        entity=\"bentocg\",\n",
        "        id=experiment_id,\n",
        "    )\n",
        "    experiment.config.update(\n",
        "        dict(\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            learning_rate=learning_rate,\n",
        "            augmentation_mode=augmentation_mode,\n",
        "            save_checkpoint=save_checkpoint,\n",
        "            neg_to_pos_ratio=neg_to_pos_ratio,\n",
        "            uniform_group_weights=uniform_group_weights,\n",
        "            criterion_mask=args.criterion_mask,\n",
        "            alpha_count=alpha_count,\n",
        "            patience=patience,\n",
        "            amp=amp,\n",
        "            model_architecture=args.model_architecture,\n",
        "            dropout_regression=args.dropout_regression,\n",
        "            test_time_augmentation=args.tta,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    logging.info(\n",
        "        f\"\"\"Starting training experiment {experiment_id}:\n",
        "        Epochs:          {epochs}\n",
        "        Batch size:      {batch_size}\n",
        "        Learning rate:   {learning_rate}\n",
        "        Training size:   {n_train}\n",
        "        Validation size: {n_val}\n",
        "        Checkpoints:     {save_checkpoint}\n",
        "        Device:          {device.type}\n",
        "        Patience:        {patience}\n",
        "        Decay factor:    {decay_factor}\n",
        "        Criterion count: {criterion_count}\n",
        "        Criterion mask:  {criterion_mask}\n",
        "        Count loss weight:     {alpha_count}\n",
        "        Validation rounds per epoch: {val_rounds_per_epoch}\n",
        "        Uniform group weights: {uniform_group_weights}\n",
        "        Negative to positive ratio:  {neg_to_pos_ratio}\n",
        "        Augmentation mode: {augmentation_mode}\n",
        "        Mixed Precision: {amp}\n",
        "        Test-time-augmentation: {args.tta}\n",
        "    \"\"\"\n",
        "    )\n",
        "\n",
        "    # Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
        "    optimizer = optim.AdamW(net.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, \"max\", patience=patience, factor=decay_factor\n",
        "    )  # goal: maximize Dice score\n",
        "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
        "    global_step = 0\n",
        "    non_improving = 0  # Number of validation epochs without improvement (quit after 15)\n",
        "    best_f1 = 0\n",
        "\n",
        "    # Begin training\n",
        "    for epoch in range(epochs):\n",
        "        net.train()\n",
        "        epoch_loss = 0\n",
        "        with tqdm(\n",
        "            total=n_train, desc=f\"Epoch {epoch + 1}/{epochs}\", unit=\"img\"\n",
        "        ) as pbar:\n",
        "            for images, true_counts, _, true_masks in train_loader:\n",
        "\n",
        "                assert images.shape[1] == 1, (\n",
        "                    f\"Network has been defined with 1 input channel, \"\n",
        "                    f\"but loaded images have {images.shape[1]} channels. Please check that \"\n",
        "                    \"the images are loaded correctly.\"\n",
        "                )\n",
        "\n",
        "                images = images.to(device=device, dtype=torch.float32)\n",
        "                true_masks = true_masks.to(device=device, dtype=torch.float32)\n",
        "                true_counts = true_counts.to(\n",
        "                    device=device, dtype=torch.float32\n",
        "                ).reshape(-1, 1)\n",
        "\n",
        "                with torch.cuda.amp.autocast(enabled=amp):\n",
        "                    pred_masks, pred_counts = net(images)\n",
        "                    loss_mask = criterion_mask(pred_masks, true_masks)\n",
        "                    loss_count = criterion_count(pred_counts, true_counts)\n",
        "                    loss = (1 - alpha_count) * loss_mask + alpha_count * loss_count\n",
        "\n",
        "                optimizer.zero_grad(set_to_none=True)\n",
        "                grad_scaler.scale(loss).backward()\n",
        "                grad_scaler.step(optimizer)\n",
        "                grad_scaler.update()\n",
        "\n",
        "                pbar.update(images.shape[0])\n",
        "                global_step += 1\n",
        "                epoch_loss += loss.item()\n",
        "                experiment.log(\n",
        "                    {\n",
        "                        \"train loss (total)\": loss.item(),\n",
        "                        \"train loss (count)\": loss_count.item(),\n",
        "                        \"train loss (mask)\": loss_mask.item(),\n",
        "                        \"step\": global_step,\n",
        "                        \"epoch\": epoch,\n",
        "                    }\n",
        "                )\n",
        "                pbar.set_postfix(**{\"total loss (batch)\": loss.item()})\n",
        "                pbar.set_postfix(**{\"mask loss (batch)\": loss_mask.item()})\n",
        "                pbar.set_postfix(**{\"count loss (batch)\": loss_count.item()})\n",
        "\n",
        "                # Evaluation round (n rounds per epoch)\n",
        "                division_step = n_train // (batch_size * val_rounds_per_epoch)\n",
        "                if division_step > 0:\n",
        "                    if global_step % division_step == 0:\n",
        "                        with torch.cuda.amp.autocast(enabled=amp):\n",
        "                            (\n",
        "                                f1_score,\n",
        "                                precision,\n",
        "                                recall,\n",
        "                                dice_score,\n",
        "                                count_mae,\n",
        "                            ) = validate_unet(net, val_loader, device)\n",
        "                            scheduler.step(f1_score)\n",
        "\n",
        "                        logging.info(\"Validation F1 score: {}\".format(f1_score))\n",
        "                        grid_size = 6\n",
        "                        p = torch.tensor([1 / len(images)] * len(images))\n",
        "                        idcs = p.multinomial(min(grid_size, len(images)))\n",
        "                        images = inv_normalize(images)[idcs].detach()\n",
        "                        pred_masks = torch.sigmoid(pred_masks[idcs])\n",
        "                        pred_masks = (pred_masks > 0.5).detach().float() * 255\n",
        "                        true_masks = true_masks[idcs] * 255\n",
        "                        images = torch.clamp(images, 0, 1) * 255\n",
        "                        grid = torchvision.utils.make_grid(\n",
        "                            torch.vstack(\n",
        "                                [\n",
        "                                    images,\n",
        "                                    true_masks.repeat(1, 1, 1, 1),\n",
        "                                    pred_masks.repeat(1, 1, 1, 1),\n",
        "                                ]\n",
        "                            ),\n",
        "                            nrow=grid_size,\n",
        "                            value_range=(0, 255),\n",
        "                            scale_each=True,\n",
        "                        )\n",
        "                        grid = torch.unsqueeze(grid, 0)\n",
        "                        experiment.log(\n",
        "                            {\n",
        "                                \"learning rate\": optimizer.param_groups[0][\"lr\"],\n",
        "                                \"validation instance f1\": f1_score,\n",
        "                                \"validation instance precision\": precision,\n",
        "                                \"validation instance recall\": recall,\n",
        "                                \"validation count MAE\": count_mae,\n",
        "                                \"validation pixel dice\": dice_score,\n",
        "                                \"output\": wandb.Image(grid),\n",
        "                                \"step\": global_step,\n",
        "                                \"epoch\": epoch,\n",
        "                            }\n",
        "                        )\n",
        "\n",
        "                        # Check if f1-score improved, stop if it didn't for 15 validation rounds\n",
        "                        if f1_score > best_f1:\n",
        "                            best_f1 = f1_score\n",
        "                            experiment.log({\"best validation instance f1\": best_f1})\n",
        "                            non_improving = 0\n",
        "\n",
        "                        else:\n",
        "                            non_improving += 1\n",
        "                            if non_improving > 3 * val_rounds_per_epoch:\n",
        "                                return best_f1\n",
        "\n",
        "        if save_checkpoint:\n",
        "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
        "            torch.save(net.state_dict(), f\"{dir_checkpoint}/{experiment_id}.pth\")\n",
        "            logging.info(\n",
        "                f\"Checkpoint for experiment {experiment_id} epoch {epoch + 1} saved!\"\n",
        "            )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    args = get_args()\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    logging.info(f\"Using device {device}\")\n",
        "    experiment_id = str(uuid.uuid4())\n",
        "\n",
        "    # Set up loss function for masks\n",
        "    if args.criterion_mask == \"Dice\":\n",
        "        criterion_mask = DiceLoss()\n",
        "    elif args.criterion_mask == \"SoftDice\":\n",
        "        criterion_mask = SoftDiceLoss()\n",
        "    elif args.criterion_mask == \"Focal\":\n",
        "        criterion_mask = FocalLoss()\n",
        "    else:\n",
        "        criterion_mask = MixedLoss()\n",
        "\n",
        "    # Instantiate model\n",
        "    net = get_semantic_segmentation_model(\n",
        "        model_architecture=args.model_architecture,\n",
        "        patch_size=args.patch_size,\n",
        "        dropout_regression=args.dropout_regression,\n",
        "    )\n",
        "    net.to(device=device)\n",
        "\n",
        "    # Use data-parallel when requested\n",
        "    if args.data_parallel:\n",
        "        device_ids = [int(ele) for ele in args.data_parallel.split(\"_\")]\n",
        "        net = nn.DataParallel(net, device_ids=device_ids)\n",
        "\n",
        "    # Set random seed\n",
        "    seed_all(0)\n",
        "\n",
        "    # Start training loop\n",
        "    best_f1 = 0\n",
        "    try:\n",
        "        best_f1 = train_net(\n",
        "            net=net,\n",
        "            epochs=args.epochs,\n",
        "            alpha_count=args.alpha_count,\n",
        "            training_dir=args.training_dir,\n",
        "            uniform_group_weights=args.uniform_group_weights,\n",
        "            augmentation_mode=args.augmentation_mode,\n",
        "            patch_size=args.patch_size,\n",
        "            num_workers=args.num_workers,\n",
        "            experiment_id=experiment_id,\n",
        "            batch_size=args.batch_size,\n",
        "            criterion_mask=criterion_mask,\n",
        "            neg_to_pos_ratio=args.neg_to_pos_ratio,\n",
        "            patience=args.patience,\n",
        "            val_rounds_per_epoch=args.val_rounds_per_epoch,\n",
        "            learning_rate=args.lr,\n",
        "            device=device,\n",
        "            amp=bool(args.amp),\n",
        "        )\n",
        "    except KeyboardInterrupt:\n",
        "        logging.info(\"Training interrupted, continuing to testing\")\n",
        "\n",
        "    # Start test loop\n",
        "    if best_f1 < args.min_val_f1_test:\n",
        "        logging.info(\"Best validation f-1 score too low, skipping testing\")\n",
        "        exit()\n",
        "\n",
        "    logging.info(\"Started testing\")\n",
        "\n",
        "    try:\n",
        "        if args.tta:\n",
        "            net = SegmentationRegTTAWrapper(\n",
        "                model=net, transforms=ttach.aliases.d4_transform()\n",
        "            )\n",
        "        test_unet(\n",
        "            device=device,\n",
        "            net=net,\n",
        "            test_dir=f\"../{args.training_dir}/test\",\n",
        "            experiment_id=experiment_id,\n",
        "            batch_size=args.batch_size * 2,\n",
        "            num_workers=args.num_workers,\n",
        "            amp=bool(args.amp),\n",
        "            threshold=0.5,\n",
        "            match_distance=1.5,\n",
        "            nms_distance=1.0,\n",
        "            ground_truth_gdf=args.test_gdf,\n",
        "        )\n",
        "        logging.info(\"Testing complete saving model checkpoint\")\n",
        "\n",
        "        # Save model checkpoint\n",
        "        os.makedirs(\"../checkpoints\", exist_ok=True)\n",
        "        torch.save(net.state_dict(), f\"../checkpoints/{experiment_id}.pth\")\n",
        "    except KeyboardInterrupt:\n",
        "        logging.info(\"Testing interruped\")\n",
        "        sys.exit(0)"
      ],
      "metadata": {
        "id": "wS6Sda2BKVo4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}